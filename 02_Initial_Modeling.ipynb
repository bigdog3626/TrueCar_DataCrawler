{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccca51a4-7c8e-46bc-b3c1-89399382201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trim</th>\n",
       "      <th>mileage</th>\n",
       "      <th>location_state</th>\n",
       "      <th>location_city</th>\n",
       "      <th>num_accidents</th>\n",
       "      <th>num_owners</th>\n",
       "      <th>usage</th>\n",
       "      <th>...</th>\n",
       "      <th>int_color_Black</th>\n",
       "      <th>int_color_Blue</th>\n",
       "      <th>int_color_Brown</th>\n",
       "      <th>int_color_Gray</th>\n",
       "      <th>int_color_Orange</th>\n",
       "      <th>int_color_Red</th>\n",
       "      <th>int_color_Silver</th>\n",
       "      <th>int_color_Unknown</th>\n",
       "      <th>int_color_White</th>\n",
       "      <th>int_color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Z3</td>\n",
       "      <td>Roadster 1.9L</td>\n",
       "      <td>89677</td>\n",
       "      <td>CA</td>\n",
       "      <td>Corona</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>Personal use</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Z3</td>\n",
       "      <td>Roadster 1.9L</td>\n",
       "      <td>76790</td>\n",
       "      <td>IL</td>\n",
       "      <td>McCook</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>Personal use</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL 320 Roadster</td>\n",
       "      <td>134000</td>\n",
       "      <td>ND</td>\n",
       "      <td>Dickinson</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>Personal use</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL 500 Roadster</td>\n",
       "      <td>156753</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>Personal use</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL</td>\n",
       "      <td>SL 500 Roadster</td>\n",
       "      <td>76923</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>Personal use</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           make model             trim  mileage location_state  \\\n",
       "0  1997            BMW    Z3    Roadster 1.9L    89677             CA   \n",
       "1  1997            BMW    Z3    Roadster 1.9L    76790             IL   \n",
       "2  1997  Mercedes-Benz    SL  SL 320 Roadster   134000             ND   \n",
       "3  1997  Mercedes-Benz    SL  SL 500 Roadster   156753             IL   \n",
       "4  1997  Mercedes-Benz    SL  SL 500 Roadster    76923             AZ   \n",
       "\n",
       "  location_city  num_accidents  num_owners         usage  ...  \\\n",
       "0        Corona           0.00           3  Personal use  ...   \n",
       "1        McCook           0.00           4  Personal use  ...   \n",
       "2     Dickinson           0.00           3  Personal use  ...   \n",
       "3       Chicago           0.00           9  Personal use  ...   \n",
       "4         Tempe           0.00           8  Personal use  ...   \n",
       "\n",
       "   int_color_Black int_color_Blue  int_color_Brown  int_color_Gray  \\\n",
       "0                0              0                0               0   \n",
       "1                1              0                0               0   \n",
       "2                0              0                0               0   \n",
       "3                0              0                0               0   \n",
       "4                0              0                0               0   \n",
       "\n",
       "   int_color_Orange  int_color_Red  int_color_Silver  int_color_Unknown  \\\n",
       "0                 0              0                 0                  1   \n",
       "1                 0              0                 0                  0   \n",
       "2                 0              0                 0                  0   \n",
       "3                 0              0                 0                  1   \n",
       "4                 0              0                 0                  1   \n",
       "\n",
       "   int_color_White  int_color_Yellow  \n",
       "0                0                 0  \n",
       "1                0                 0  \n",
       "2                0                 0  \n",
       "3                0                 0  \n",
       "4                0                 0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "import warnings\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, GammaRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "RS=42\n",
    "TARGET='price'\n",
    "N_SPLITS=5\n",
    "\n",
    "\n",
    "data = './Data/used_car_fe'\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012af4b3-1536-44b0-ac84-052b33ff9c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trim_counts = df.trim.value_counts()\n",
    "trim_counts = trim_counts[trim_counts >= 25]  # filter trims with counts >= 25\n",
    "df_filtered = df[df.trim.isin(trim_counts.index)]  # filter rows with remaining trimm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b16fccf-1c98-4746-bea6-319c980b414a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_filtered = pd.get_dummies(df_filtered, columns=['make','usage','mileage_binned'])\n",
    "df = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d39bcd-29b8-4713-9293-bd83fd4abdb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LE = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d343b6e1-bb0f-4b4d-af43-9aa7fbd729d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['trim'] = LE.fit_transform(df['trim'])\n",
    "df['model'] = LE.fit_transform(df['model'])\n",
    "df['location_state'] = LE.fit_transform(df['location_state'])\n",
    "df['location_city'] = LE.fit_transform(df['location_city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196cdbc4-c5c4-4191-8fa2-c758cfdb2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27592, 47)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df[TARGET]\n",
    "df = df.drop([TARGET], axis=1)\n",
    "df[TARGET]= temp\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76656e9b-ee96-44bb-b959-430eb55872b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13192720-1be8-4351-a068-024a2029d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "# Lets make some inital modeling and define some Quality of Life improving functions.\n",
    "def print_model_locations(model_list):\n",
    "    print(\"-\"*80)\n",
    "    for i,model in enumerate(model_list):\n",
    "        print(model)\n",
    "        print(f\"{model.__class__.__name__:50} at index {i}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        \n",
    "        \n",
    "# K Fold Model Evaluator\n",
    "def evaluate_model_kf(model, train, target, n_splits=N_SPLITS,  random_state=RS):\n",
    "    n= 0\n",
    "    RMSES = []\n",
    "    kf = KFold(\n",
    "        n_splits=n_splits, random_state=random_state\n",
    "    )\n",
    "    for trn_idx, test_idx in kf.split(train,target):\n",
    "        X_tr,X_val=train.iloc[trn_idx],train.iloc[test_idx]\n",
    "        y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n",
    "        model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n",
    "        RMSES.append(rmse(y_val, model.predict(X_val)))\n",
    "        print(f\"fold: {n+1} ==> RMSE: {RMSES[n]}\")\n",
    "        n+=1\n",
    "    return np.mean(RMSES)\n",
    "\n",
    "\n",
    "# Model Evaluator\n",
    "def model_evaluator(model_list):\n",
    "    print(\"-\"*80)\n",
    "    for reg in model_list:\n",
    "        reg_name=reg.__class__.__name__\n",
    "        score = evaluate_model_kf(reg,X, y, n_splits=N_SPLITS, random_state=RS)\n",
    "        print(f\"Fitting Baseline {reg_name} done\")\n",
    "        print(f\"RMSES: {score}\")\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8856a12e-4641-4bdd-b52c-a68432b07059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...)\n",
      "XGBRegressor                                       at index 0\n",
      "--------------------------------------------------------------------------------\n",
      "LGBMRegressor(metric='rmse')\n",
      "LGBMRegressor                                      at index 1\n",
      "--------------------------------------------------------------------------------\n",
      "<catboost.core.CatBoostRegressor object at 0x7f13f4275240>\n",
      "CatBoostRegressor                                  at index 2\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reg_list=[\n",
    "    xgb.XGBRegressor(tree_method='gpu_hist'),\n",
    "    lgbm.LGBMRegressor(metric='rmse'),\n",
    "    cb.CatBoostRegressor(verbose=0)\n",
    "]\n",
    "print_model_locations(reg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1152af76-ace0-4222-82ca-df60b8623b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "fold: 1 ==> RMSE: 0.2781232912789587\n",
      "fold: 2 ==> RMSE: 0.17751371012458025\n",
      "fold: 3 ==> RMSE: 0.12652306318754816\n",
      "fold: 4 ==> RMSE: 0.12578896506191303\n",
      "fold: 5 ==> RMSE: 0.1450093276589908\n",
      "Fitting Baseline XGBRegressor done\n",
      "RMSES: 0.17059167146239818\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 1 ==> RMSE: 0.3216394140998013\n",
      "fold: 2 ==> RMSE: 0.18397193889967212\n",
      "fold: 3 ==> RMSE: 0.15348546392484258\n",
      "fold: 4 ==> RMSE: 0.13919539561991634\n",
      "fold: 5 ==> RMSE: 0.1775525027337844\n",
      "Fitting Baseline LGBMRegressor done\n",
      "RMSES: 0.19516894305560337\n",
      "--------------------------------------------------------------------------------\n",
      "fold: 1 ==> RMSE: 0.31861852713565003\n",
      "fold: 2 ==> RMSE: 0.1450250116480755\n",
      "fold: 3 ==> RMSE: 0.10864511641394556\n",
      "fold: 4 ==> RMSE: 0.12760023250417346\n",
      "fold: 5 ==> RMSE: 0.1399621931447064\n",
      "Fitting Baseline CatBoostRegressor done\n",
      "RMSES: 0.16797021616931018\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 1min 37s, sys: 9.21 s, total: 1min 47s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_evaluator(reg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75251de7-80d6-4253-a16b-55eae09a499f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare optuna objective\n",
    "def objective(trial,data=X,target=y):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=RS)\n",
    "    param = {\n",
    "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [6000]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
    "        'random_state': trial.suggest_categorical('random_state', [RS]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    RMSE = rmse(test_y, preds)\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b270692-af13-418a-9088-25083b628a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-20 00:48:41,606]\u001b[0m A new study created in memory with name: no-name-c4aab506-d566-469a-8e2f-662536020672\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:48:48,800]\u001b[0m Trial 0 finished with value: 0.09671211332825916 and parameters: {'lambda': 1.0663419530723752, 'alpha': 0.6059350528571593, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 37}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:49:02,640]\u001b[0m Trial 1 finished with value: 0.10965333696247077 and parameters: {'lambda': 0.10038736715669085, 'alpha': 9.42574995917851, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 16}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:49:20,904]\u001b[0m Trial 2 finished with value: 0.10504389921882995 and parameters: {'lambda': 0.007063889571092111, 'alpha': 0.006683235265521592, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.012, 'n_estimators': 6000, 'max_depth': 13, 'random_state': 42, 'min_child_weight': 171}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:49:33,741]\u001b[0m Trial 3 finished with value: 0.10387670056006561 and parameters: {'lambda': 0.9269308858019093, 'alpha': 6.579656239890085, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.008, 'n_estimators': 6000, 'max_depth': 15, 'random_state': 42, 'min_child_weight': 28}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:49:46,382]\u001b[0m Trial 4 finished with value: 0.12075986037570086 and parameters: {'lambda': 1.4627571405594253, 'alpha': 0.11237380839960064, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.008, 'n_estimators': 6000, 'max_depth': 9, 'random_state': 42, 'min_child_weight': 299}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:50:00,311]\u001b[0m Trial 5 finished with value: 0.10381567380682845 and parameters: {'lambda': 0.10789806932686148, 'alpha': 0.003981306217917863, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.016, 'n_estimators': 6000, 'max_depth': 9, 'random_state': 42, 'min_child_weight': 235}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:50:14,777]\u001b[0m Trial 6 finished with value: 0.10126246739982019 and parameters: {'lambda': 0.0030546738598965246, 'alpha': 2.0335885659527193, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.012, 'n_estimators': 6000, 'max_depth': 15, 'random_state': 42, 'min_child_weight': 24}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:50:29,586]\u001b[0m Trial 7 finished with value: 0.10009775878104557 and parameters: {'lambda': 0.009153375549485542, 'alpha': 3.1968374862524516, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 6000, 'max_depth': 13, 'random_state': 42, 'min_child_weight': 46}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:50:40,411]\u001b[0m Trial 8 finished with value: 0.11160449489933047 and parameters: {'lambda': 0.001671225500804281, 'alpha': 0.012959275297544193, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 6000, 'max_depth': 7, 'random_state': 42, 'min_child_weight': 277}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:50:49,094]\u001b[0m Trial 9 finished with value: 0.1127679901615164 and parameters: {'lambda': 0.004989404975528633, 'alpha': 0.0010217330403660817, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.008, 'n_estimators': 6000, 'max_depth': 5, 'random_state': 42, 'min_child_weight': 262}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:51:01,401]\u001b[0m Trial 10 finished with value: 0.09980960096809197 and parameters: {'lambda': 7.6162549638243755, 'alpha': 0.39330860758029584, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 117}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:51:13,250]\u001b[0m Trial 11 finished with value: 0.09949204829356392 and parameters: {'lambda': 6.597695752450977, 'alpha': 0.4231372524508438, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 106}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:51:26,624]\u001b[0m Trial 12 finished with value: 0.09881638696756366 and parameters: {'lambda': 9.681521122933793, 'alpha': 0.5743399183346952, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 95}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:51:41,829]\u001b[0m Trial 13 finished with value: 0.09905546337919306 and parameters: {'lambda': 1.6038051422898152, 'alpha': 0.5904037974600855, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 17, 'random_state': 42, 'min_child_weight': 81}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:51:56,398]\u001b[0m Trial 14 finished with value: 0.1015531241120517 and parameters: {'lambda': 9.030590512014498, 'alpha': 0.07635624349357148, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 175}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:52:11,309]\u001b[0m Trial 15 finished with value: 0.10189354061047927 and parameters: {'lambda': 0.5656130895355436, 'alpha': 1.7725088849198378, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.014, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 73}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:52:22,561]\u001b[0m Trial 16 finished with value: 0.10242416280608538 and parameters: {'lambda': 2.8708351466693345, 'alpha': 0.10280122148659673, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 7, 'random_state': 42, 'min_child_weight': 131}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:52:31,350]\u001b[0m Trial 17 finished with value: 0.09989554764192882 and parameters: {'lambda': 0.38338110674120435, 'alpha': 0.9361164715968692, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 6000, 'max_depth': 5, 'random_state': 42, 'min_child_weight': 71}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:52:50,204]\u001b[0m Trial 18 finished with value: 0.10522009912784118 and parameters: {'lambda': 3.4153656066874607, 'alpha': 0.25981110915155153, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 6000, 'max_depth': 17, 'random_state': 42, 'min_child_weight': 207}. Best is trial 0 with value: 0.09671211332825916.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:53:01,400]\u001b[0m Trial 19 finished with value: 0.09498438550158199 and parameters: {'lambda': 0.3294172329593077, 'alpha': 0.9762720616822073, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 4}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:53:13,707]\u001b[0m Trial 20 finished with value: 0.10333267865541405 and parameters: {'lambda': 0.2473197195254169, 'alpha': 3.4922311312290852, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 5}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:53:25,857]\u001b[0m Trial 21 finished with value: 0.0982492325826506 and parameters: {'lambda': 0.8070257322023022, 'alpha': 1.066097402070278, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 50}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:53:41,140]\u001b[0m Trial 22 finished with value: 0.09780439482074868 and parameters: {'lambda': 0.24374756391957314, 'alpha': 1.435474630615398, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 46}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:53:55,800]\u001b[0m Trial 23 finished with value: 0.09770812976482132 and parameters: {'lambda': 0.18112476387708318, 'alpha': 1.2898328100732206, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 45}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:08,961]\u001b[0m Trial 24 finished with value: 0.09986824134878815 and parameters: {'lambda': 0.03135293492506019, 'alpha': 3.820872025576202, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 1}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:17,042]\u001b[0m Trial 25 finished with value: 0.09654670103637275 and parameters: {'lambda': 0.04931374007441801, 'alpha': 0.22623075195515946, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 11, 'random_state': 42, 'min_child_weight': 54}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:30,811]\u001b[0m Trial 26 finished with value: 0.09987852695265623 and parameters: {'lambda': 0.047914692198719015, 'alpha': 0.18170038918684236, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.014, 'n_estimators': 6000, 'max_depth': 9, 'random_state': 42, 'min_child_weight': 146}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:39,632]\u001b[0m Trial 27 finished with value: 0.09730628317750163 and parameters: {'lambda': 0.49926093693071766, 'alpha': 0.054102791223059186, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 15, 'random_state': 42, 'min_child_weight': 59}. Best is trial 19 with value: 0.09498438550158199.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:48,121]\u001b[0m Trial 28 finished with value: 0.09400678594181001 and parameters: {'lambda': 0.03886751006294093, 'alpha': 0.21057654805358594, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 17, 'random_state': 42, 'min_child_weight': 25}. Best is trial 28 with value: 0.09400678594181001.\u001b[0m\n",
      "\u001b[32m[I 2023-03-20 00:54:56,974]\u001b[0m Trial 29 finished with value: 0.09414902878521574 and parameters: {'lambda': 0.0261615265076489, 'alpha': 0.30411044709217344, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 17, 'random_state': 42, 'min_child_weight': 27}. Best is trial 28 with value: 0.09400678594181001.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial: {'lambda': 0.03886751006294093, 'alpha': 0.21057654805358594, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 6000, 'max_depth': 17, 'random_state': 42, 'min_child_weight': 25}\n",
      "Best RMSE: 0.09400678594181001\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30, gc_after_trial=True)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print(f\"Best RMSE: {study.best_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_venv",
   "language": "python",
   "name": "car_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
